{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas and Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` is a package that grants one access to a range of powerful data analysis tools. This, along with packages such as `numpy` are ubiquitous, and you will find yourself importing these two packages almost every time you start a data science project. \n",
    "\n",
    "\n",
    "The value of Pandas comes from the fact that it allows us to define fundamental data structures that are: \n",
    "\n",
    "* Flexible and intuitive\n",
    "* Suitable for many economic settings (The name Pandas comes from 'Panel Data')\n",
    "\n",
    "In laymans terms, we can think of this package as giving us access to 'excel-like' data structrures that preserve the stucture of .csv and .xlsx files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the package -- it is standard convention to import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/varunsatish/Coding-Tutorials/master/Data/titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.250</td>\n",
       "      <td>A54</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.925</td>\n",
       "      <td>B28</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.100</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.050</td>\n",
       "      <td>C19</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   NaN      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket    Fare Cabin     Embarked  \n",
       "0      0         A/5 21171   7.250   A54            S  \n",
       "1      0          PC 17599     NaN   C85            C  \n",
       "2      0  STON/O2. 3101282   7.925   B28  Southampton  \n",
       "3      0            113803  53.100  C123            S  \n",
       "4      0            373450   8.050   C19            S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do you notice anything wrong with the data?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Data...\n",
    "\n",
    "Before we start any sort of analysis, it is first useful to have a look at the data and if possible read it's documentation. Generally, datasets that you find will come along with some form of documentation describing how the dtaa was collected, what the variables are (and **importantly** how they were coded) and so forth. \n",
    "\n",
    "This dataset is made up of individuals who were on board the 'Titanic', an oceanliner which after hitting an iceberg, famously sunk in the Atlantic Ocean in 1912. \n",
    "\n",
    "![Titanic](https://upload.wikimedia.org/wikipedia/commons/thumb/6/6e/St%C3%B6wer_Titanic.jpg/350px-St%C3%B6wer_Titanic.jpg) \n",
    "\n",
    "\n",
    "\n",
    "This dataset is a really popular beginner dataset on [Kaggle]. Kaggle is an online data science community that runs competitions, tutorials and projects utilising tools such as statistics and machine learning. If you have found these workshops interesting and would like to use some of the skills you have learnt, check it out !\n",
    "\n",
    "[Kaggle]: (https://www.kaggle.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Titanic documentation](https://github.com/varunsatish/Coding-Tutorials/blob/master/images/titanic_doc.jpg?raw=true) \n",
    "\n",
    "\n",
    "**Note**: We have modifed the datset from the original just so that it fits into our tutorial a little easier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![8020](https://raw.githubusercontent.com/varunsatish/Coding-Tutorials/master/images/80-20_datascience.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![meagher](https://raw.githubusercontent.com/varunsatish/Coding-Tutorials/master/images/meagher_tweet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with missing values\n",
    "\n",
    "**Important Note**: There are very important statistical implications of dealing with missing values. In practice you really need to be careful about this, this tutorial is simply demonstrating how you can deal with missing values from a programming perspective **not** a statistical one.\n",
    "\n",
    "Missing values plague almost every dataset, we can choose to deal with them in different ways. Observations which have been specfied as `NaN` (standing for 'not a number') are examples of undefined or unrepresentable values. They can be produced either because there is no observation, or because of some problematic mathematical operation (for example division by `0`). \n",
    "\n",
    "Sometimes it may be appropriate to just fill these values with 0, other times it may be more appripriate to fill these values with some form of imputation (meaning, some sort of calculated value). The `numpy` package is really useful for these sorts of applications. \n",
    "\n",
    "As we can see, the `Age` category contains some missing values. It doesn't really make sense to fill in these missing values with a 0, instead we may want to fill in these values with the average. There are many ways we can do this, however the `numpy` method is extremely quick and elegant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.250</td>\n",
       "      <td>A54</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.925</td>\n",
       "      <td>B28</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>23.760011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.100</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.050</td>\n",
       "      <td>C19</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex        Age  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.000000   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.000000   \n",
       "2                             Heikkinen, Miss. Laina  female  26.000000   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  23.760011   \n",
       "4                           Allen, Mr. William Henry    male  35.000000   \n",
       "\n",
       "   SibSp  Parch            Ticket    Fare Cabin     Embarked  \n",
       "0      1      0         A/5 21171   7.250   A54            S  \n",
       "1      1      0          PC 17599     NaN   C85            C  \n",
       "2      0      0  STON/O2. 3101282   7.925   B28  Southampton  \n",
       "3      1      0            113803  53.100  C123            S  \n",
       "4      0      0            373450   8.050   C19            S  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "Strictly speaking we should divide by length of values that are not NaN.\n",
    "This is purely illustrative, not necessarily statistically accurate\n",
    "\"\"\"\n",
    "\n",
    "ave_age = df['Age'].sum()/len(df['Age'])  # .sum() sums down column of a dataframe\n",
    "\n",
    "\n",
    "df['Age'] = df['Age'].fillna(ave_age)  # Filling all NaN values with average age\n",
    "\n",
    "df.head()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, notice the 3rd observation. Does it make any sense to speak about ages as a fraction? Maybe, depending on your analysis, but in general no. So what can we do? We can utilise the `int()` function which turns float values into integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.250</td>\n",
       "      <td>A54</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.925</td>\n",
       "      <td>B28</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.100</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.050</td>\n",
       "      <td>C19</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex  Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male   22      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
       "2                             Heikkinen, Miss. Laina  female   26      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   23      1   \n",
       "4                           Allen, Mr. William Henry    male   35      0   \n",
       "\n",
       "   Parch            Ticket    Fare Cabin     Embarked  \n",
       "0      0         A/5 21171   7.250   A54            S  \n",
       "1      0          PC 17599     NaN   C85            C  \n",
       "2      0  STON/O2. 3101282   7.925   B28  Southampton  \n",
       "3      0            113803  53.100  C123            S  \n",
       "4      0            373450   8.050   C19            S  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age'] = [int(age) for age in df['Age']]  # For every age in the column, turn it into an integer\n",
    "\n",
    "# An alternative method:\n",
    "\n",
    "df['Age'].astype(int)  # Produces the same output. The code above is a generalised form.\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Words\n",
    "\n",
    "Sometimes we have data that has errors relating to the way that words (more generally 'strings') are presented. For example, maybe the dataset displays `University` as `University of Sydney` for some observations but `USYD` for others. This is a problem, because if we want to work with data we need some level of consistency across observations.\n",
    "\n",
    "So how can we deal with problems such as this? \n",
    "\n",
    "The first place to start is to have a look at your data and check for any 'irregularities'. In our dataset, we may notice that for some observations, we observe `Southampton` but `S` for others. We know that these two should be consistent (because of the documentation). Now, we want to make every observation that embarked at `Southampton` to be coded with `S`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.250</td>\n",
       "      <td>A54</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.925</td>\n",
       "      <td>B28</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>23.760011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.100</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.050</td>\n",
       "      <td>C19</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex        Age  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.000000   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.000000   \n",
       "2                             Heikkinen, Miss. Laina  female  26.000000   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  23.760011   \n",
       "4                           Allen, Mr. William Henry    male  35.000000   \n",
       "\n",
       "   SibSp  Parch            Ticket    Fare Cabin Embarked  \n",
       "0      1      0         A/5 21171   7.250   A54        S  \n",
       "1      1      0          PC 17599     NaN   C85        C  \n",
       "2      0      0  STON/O2. 3101282   7.925   B28        S  \n",
       "3      1      0            113803  53.100  C123        S  \n",
       "4      0      0            373450   8.050   C19        S  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_string = 'S'\n",
    "old_string = 'Southampton'\n",
    "\n",
    "df['Embarked'] = df['Embarked'].replace(old_string, new_string)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prefixes and Suffixes \n",
    "\n",
    "One issue that commonly arises when using financial or historical data comes from suffixes and prefixes. Sometimes, when we download data, there are annoying letter or numbers attached to the start or the ends of our observations. For example, suppose we are intersted in the `Cabin` variable. Lets suppose we want to do some calculations on this variable, maybe using `numpy`. Do you see any problems?\n",
    "\n",
    "I will show you two ways of dealing with this problem, the first using anonymous 'lambda functions' and the second using list comprehension.\n",
    "\n",
    "### Anonymous Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using an anonymous function to get rid of the letter prefixes on the 'Cabin' variable\n",
    "\n",
    "prefixer = lambda x: x[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this function do? Let's see a concrete example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bcd'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters = 'abcd'\n",
    "\n",
    "letters[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              54\n",
       "1              85\n",
       "2              28\n",
       "3             123\n",
       "4              19\n",
       "5              an\n",
       "6              46\n",
       "7              an\n",
       "8              an\n",
       "9              an\n",
       "10              6\n",
       "11            103\n",
       "12             an\n",
       "13             an\n",
       "14             an\n",
       "15             an\n",
       "16             an\n",
       "17             an\n",
       "18             an\n",
       "19             an\n",
       "20             an\n",
       "21             56\n",
       "22             an\n",
       "23              6\n",
       "24             an\n",
       "25             an\n",
       "26             an\n",
       "27     23 C25 C27\n",
       "28             an\n",
       "29             an\n",
       "          ...    \n",
       "861            an\n",
       "862            17\n",
       "863            an\n",
       "864            an\n",
       "865            an\n",
       "866            an\n",
       "867            24\n",
       "868            an\n",
       "869            an\n",
       "870            an\n",
       "871            35\n",
       "872    51 B53 B55\n",
       "873            an\n",
       "874            an\n",
       "875            an\n",
       "876            an\n",
       "877            an\n",
       "878            an\n",
       "879            50\n",
       "880            an\n",
       "881            an\n",
       "882            an\n",
       "883            an\n",
       "884            an\n",
       "885            an\n",
       "886            an\n",
       "887            42\n",
       "888            an\n",
       "889           148\n",
       "890            an\n",
       "Name: Cabin, Length: 891, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making sure everything is a string\n",
    "\n",
    "df['Cabin'] = [str(x) for x in df['Cabin']]\n",
    "df['Cabin'].apply(lambda x: x[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do this more directly with list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['54',\n",
       " '85',\n",
       " '28',\n",
       " '123',\n",
       " '19',\n",
       " 'an',\n",
       " '46',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '6',\n",
       " '103',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '56',\n",
       " 'an',\n",
       " '6',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '23 C25 C27',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '78',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '33',\n",
       " 'an',\n",
       " '30',\n",
       " '52',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '28',\n",
       " '83',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '33',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " ' G73',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '23 C25 C27',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '31',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '5',\n",
       " '10 D12',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '26',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '110',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '58 B60',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '101',\n",
       " '26',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " ' E69',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '47',\n",
       " '123',\n",
       " 'an',\n",
       " '86',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '2',\n",
       " 'an',\n",
       " 'an',\n",
       " '2',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '33',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '19',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '7',\n",
       " 'an',\n",
       " 'an',\n",
       " '49',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '4',\n",
       " 'an',\n",
       " '32',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '2',\n",
       " '4',\n",
       " '80',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '6',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '31',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '36',\n",
       " 'an',\n",
       " 'an',\n",
       " '15',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '93',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '83',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '78',\n",
       " 'an',\n",
       " 'an',\n",
       " '35',\n",
       " 'an',\n",
       " 'an',\n",
       " '6',\n",
       " '87',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '77',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '67',\n",
       " '94',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '125',\n",
       " '99',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '118',\n",
       " 'an',\n",
       " '7',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '19',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '49',\n",
       " '',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '22 C26',\n",
       " '106',\n",
       " '58 B60',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '101',\n",
       " 'an',\n",
       " '22 C26',\n",
       " 'an',\n",
       " '65',\n",
       " 'an',\n",
       " '36',\n",
       " '54',\n",
       " '57 B59 B63 B66',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '7',\n",
       " '34',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '32',\n",
       " 'an',\n",
       " '',\n",
       " 'an',\n",
       " '18',\n",
       " 'an',\n",
       " '124',\n",
       " '91',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '2',\n",
       " '40',\n",
       " 'an',\n",
       " '',\n",
       " '2',\n",
       " '23 C25 C27',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '33',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '128',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '33',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '37',\n",
       " 'an',\n",
       " 'an',\n",
       " '35',\n",
       " '50',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '82',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '96 B98',\n",
       " 'an',\n",
       " 'an',\n",
       " '36',\n",
       " '6',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '78',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '10',\n",
       " '52',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '44',\n",
       " '96 B98',\n",
       " 'an',\n",
       " 'an',\n",
       " '23 C25 C27',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '34',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '104',\n",
       " 'an',\n",
       " 'an',\n",
       " '111',\n",
       " '92',\n",
       " 'an',\n",
       " 'an',\n",
       " '38',\n",
       " '21',\n",
       " 'an',\n",
       " 'an',\n",
       " '12',\n",
       " 'an',\n",
       " '63',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '',\n",
       " 'an',\n",
       " '14',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '49',\n",
       " 'an',\n",
       " '93',\n",
       " '37',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '30',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '20',\n",
       " 'an',\n",
       " '22 C26',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '79',\n",
       " '65',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '25',\n",
       " 'an',\n",
       " 'an',\n",
       " '46',\n",
       " '33',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '73',\n",
       " 'an',\n",
       " 'an',\n",
       " '18',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '95',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '38',\n",
       " 'an',\n",
       " 'an',\n",
       " '39',\n",
       " '22',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '86',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '70',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '16',\n",
       " 'an',\n",
       " '67',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '101',\n",
       " '25',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '44',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '68',\n",
       " 'an',\n",
       " '10',\n",
       " 'an',\n",
       " '68',\n",
       " 'an',\n",
       " '41',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '20',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '20',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '125',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '4',\n",
       " 'an',\n",
       " 'an',\n",
       " '19',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '50',\n",
       " 'an',\n",
       " '9',\n",
       " 'an',\n",
       " 'an',\n",
       " '23',\n",
       " 'an',\n",
       " '50',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '35',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '33',\n",
       " 'an',\n",
       " '26',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '48',\n",
       " 'an',\n",
       " 'an',\n",
       " '58',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '126',\n",
       " 'an',\n",
       " '71',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '51 B53 B55',\n",
       " 'an',\n",
       " '49',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '5',\n",
       " '20',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '68',\n",
       " ' G63',\n",
       " '62 C64',\n",
       " '24',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '24',\n",
       " 'an',\n",
       " 'an',\n",
       " '90',\n",
       " '124',\n",
       " '126',\n",
       " 'an',\n",
       " 'an',\n",
       " ' G73',\n",
       " '45',\n",
       " '101',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '8',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '5',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '101',\n",
       " 'an',\n",
       " 'an',\n",
       " '45',\n",
       " '46',\n",
       " '57 B59 B63 B66',\n",
       " 'an',\n",
       " 'an',\n",
       " '22',\n",
       " 'an',\n",
       " 'an',\n",
       " '30',\n",
       " 'an',\n",
       " 'an',\n",
       " '121',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '77',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '96 B98',\n",
       " 'an',\n",
       " '11',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '77',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '38',\n",
       " 'an',\n",
       " 'an',\n",
       " '3',\n",
       " 'an',\n",
       " '20',\n",
       " '6',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '82 B84',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '17',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '96 B98',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '36',\n",
       " 'an',\n",
       " 'an',\n",
       " '8',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '102',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '69',\n",
       " 'an',\n",
       " 'an',\n",
       " '121',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '28',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '49',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '47',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '92',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '28',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '17',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '17',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '24',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '35',\n",
       " '51 B53 B55',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '50',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " 'an',\n",
       " '42',\n",
       " 'an',\n",
       " '148',\n",
       " 'an']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[1:] for x in df['Cabin']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
